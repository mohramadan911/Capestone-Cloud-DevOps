version: 2.1

jobs:
  test-build:
    docker:
      # Use the same Docker base as the project
      - image: python:3.7.3-stretch

    working_directory: ~/repo

    steps:
      - checkout

      # Download and cache dependencies
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements.txt" }}
            # fallback to using the latest cache if no exact match is found
            - v1-dependencies-

      - run:
          name: install dependencies
          command: |
            python3 -m venv venv
            . venv/bin/activate
            make install
            # Install hadolint
            wget -O /bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.16.3/hadolint-Linux-x86_64 &&\
            chmod +x /bin/hadolint
      - save_cache:
          paths:
            - ./venv
          key: v1-dependencies-{{ checksum "requirements.txt" }}

      # run lint!
      - run:
          name: run lint
          command: |
            . venv/bin/activate 
            make lint

  upload-docker:
    docker:
      - image: circleci/golang:1.15

    working_directory: ~/repo

    steps:
      - checkout

      - setup_remote_docker:
          version: 19.03.13

      - run:
          name: Build docker container
          command: |
            docker build --tag=$DOCKER_IMAGE_NAME .
            docker image ls

      - run:
          name: Upload Docker to Dockerhub
          command: |
            echo "Docker ID and Image: $DOCKER_IMAGE_NAME"
            docker login -u="$DOCKERHUB_USERNAME" -p="$DOCKERHUB_PASSWORD"
            docker tag $DOCKER_IMAGE_NAME $DOCKERHUB_USERNAME/$DOCKER_IMAGE_NAME:$CIRCLE_WORKFLOW_ID
            docker push $DOCKERHUB_USERNAME/$DOCKER_IMAGE_NAME:$CIRCLE_WORKFLOW_ID

  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: yum install -y tar gzip
      - run:
          name: Ensure EKS network exists
          command: |
            aws cloudformation deploy \
              --template-file cloudformation/network.yml \
              --tags project=${ENVIRONMENT_NAME}-project \
              --stack-name "${ENVIRONMENT_NAME}-eks-network" \
              --region ${AWS_DEFAULT_REGION} \
              --parameter-overrides file://cloudformation/network-parameters.json
      - run:
          name: Ensure EKS Cluster exists
          command: |
            aws cloudformation deploy \
              --template-file cloudformation/cluster.yml \
              --tags project=${ENVIRONMENT_NAME}-project \
              --stack-name "${ENVIRONMENT_NAME}-eks-cluster" \
              --region ${AWS_DEFAULT_REGION} \
              --parameter-overrides file://cloudformation/cluster-parameters.json \
              --capabilities CAPABILITY_NAMED_IAM
          no_output_timeout: 15m
      - run:
          name: Ensure Nodegroup exists
          command: |
            aws cloudformation deploy \
              --template-file cloudformation/nodegroup.yml \
              --tags project=${ENVIRONMENT_NAME}-project \
              --stack-name "${ENVIRONMENT_NAME}-eks-nodegroup" \
              --region ${AWS_DEFAULT_REGION} \
              --parameter-overrides file://cloudformation/nodegroup-parameters.json \
              --capabilities CAPABILITY_NAMED_IAM
      - run:
          name: Ensure management instances exists
          command: |
            aws cloudformation deploy \
              --template-file cloudformation/management.yml \
              --tags project=${ENVIRONMENT_NAME}-project \
              --stack-name "${ENVIRONMENT_NAME}-eks-management" \
              --region ${AWS_DEFAULT_REGION} \
              --parameter-overrides file://cloudformation/management-parameters.json \
              --output text >> ~/checkIfDeployed.txt
            cat ~/checkIfDeployed.txt
      - run:
          name: Extract the IPs of the management instances for Ansible
          command: |
            echo [management] > ~/inventory.txt
            aws ec2 describe-instances \
              --region "${AWS_DEFAULT_REGION}" \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --filters "Name=tag:Name,Values=${ENVIRONMENT_NAME}-management*" \
              --output text >> ~/inventory.txt
            cat ~/inventory.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - inventory.txt
            - checkIfDeployed.txt

  configure-infrastructure:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - attach_workspace:
          at: ~/
      - add_ssh_keys: 
          fingerprints: [18:ae:75:0c:8b:9e:2c:3a:c9:3a:6a:af:bc:8b:08:f7]
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible
      - run:
          name: Configure server
          command: |
            if grep -q "No changes to deploy" ~/checkIfDeployed.txt
              then
                cat ~/inventory.txt
                echo "Our management instances are already configured."
              else
                cat ~/inventory.txt
                cd ansible
                ansible-playbook -i ~/inventory.txt configure-server.yml
              fi
          environment:
            ANSIBLE_HOST_KEY_CHECKING: false    

  configure-cluster:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys: 
          fingerprints: [18:ae:75:0c:8b:9e:2c:3a:c9:3a:6a:af:bc:8b:08:f7]
      - attach_workspace:
          at: ~/
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible
      - run:
          name: Configure server
          command: |
            if grep -q "No changes to deploy" ~/checkIfDeployed.txt
              then
                cat ~/inventory.txt
                echo "Our management instances are already configured."
              else
                cat ~/inventory.txt
                cd ansible
                ansible-playbook -i ~/inventory.txt configure-cluster.yml
              fi
          environment:
            ANSIBLE_HOST_KEY_CHECKING: false    
      - run:
          name: Wait for LoadBalancer's domain to become reachable
          command: |
            if grep -q "No changes to deploy" ~/checkIfDeployed.txt
              then
                cat ~/inventory.txt
                echo "Our management instances are already configured."
              else
                cat ~/inventory.txt
                echo "Wait 60 seconds..."
                sleep 60
              fi
          environment:
            ANSIBLE_HOST_KEY_CHECKING: false    
      

  deploy-docker:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
            - "18:ae:75:0c:8b:9e:2c:3a:c9:3a:6a:af:bc:8b:08:f7"
      - attach_workspace:
          at: ~/
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible
      - run:
          name: Deploy newest Docker Image
          command: |
            cat ~/inventory.txt
            cd ansible
            ansible-playbook -i ~/inventory.txt deploy-app.yml
          environment:
            ANSIBLE_HOST_KEY_CHECKING: false   
          no_output_timeout: 2m

workflows:
  default:
    jobs:
      - test-build
      # - upload-docker:
      #     requires:
      #       - test-build
      #     filters:
      #       branches:
      #         only: [ main ]
      - deploy-infrastructure:
          filters:
            branches:
              only: [ main ]
      - configure-infrastructure
      #     requires:
      #       - deploy-infrastructure
      - configure-cluster
      #     requires:
      #       - configure-infrastructure
      #       - upload-docker
      - deploy-docker
      #     requires:
      #       - configure-cluster
